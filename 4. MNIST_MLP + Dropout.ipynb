{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.7.0  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 모델을 설계할 때 사용하는 장비 확인\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using PyTorch version:\", torch.__version__, ' Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터 다운로드\n",
    "train_dataset = datasets.MNIST(root = \"../data/MNIST\",\n",
    "                              train = True,\n",
    "                              download = True,\n",
    "                              transform = transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root = \"../data/MNIST\",\n",
    "                             train = False,\n",
    "                             transform = transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                         batch_size = BATCH_SIZE,\n",
    "                                         shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([32, 1, 28, 28]) type: torch.FloatTensor\n",
      "y_train torch.Size([32]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "for(x_train, y_train) in train_loader:\n",
    "    print(\"X_train:\", x_train.size(), 'type:', x_train.type())\n",
    "    print(\"y_train\", y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 시각화\n",
    "pltsize = 1\n",
    "plt.figure(figsize = (10 * pltsize, pltsize))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x_train[i, :, :, :].numpy().reshape(28, 28), cmap = 'gray_r')\n",
    "    plt.title('Class: ' + str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP(Multi Layer Perceptron) 모델 설계\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        self.dropout_prob = 0.5\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = F.dropout(x, training = self.training, p = self.dropout_prob)\n",
    "        x = self.fc2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = F.dropout(x, training = self.training, p = self.dropout_prob)\n",
    "        x = self.fc3(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = F.log_softmax(x, dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Optimizer, Objective Function\n",
    "model = Net().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    model.training = True\n",
    "    \n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{}({:.0f}%)]\\tTrain Loss: {:.6f}\".format(Epoch, batch_idx * len(image),\n",
    "                                                                               len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
    "                                                                               loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    model.training=False\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim=True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000(0%)]\tTrain Loss: 2.283702\n",
      "Train Epoch: 1 [6400/60000(11%)]\tTrain Loss: 2.299196\n",
      "Train Epoch: 1 [12800/60000(21%)]\tTrain Loss: 2.305451\n",
      "Train Epoch: 1 [19200/60000(32%)]\tTrain Loss: 2.294787\n",
      "Train Epoch: 1 [25600/60000(43%)]\tTrain Loss: 2.314350\n",
      "Train Epoch: 1 [32000/60000(53%)]\tTrain Loss: 2.295473\n",
      "Train Epoch: 1 [38400/60000(64%)]\tTrain Loss: 2.305004\n",
      "Train Epoch: 1 [44800/60000(75%)]\tTrain Loss: 2.290615\n",
      "Train Epoch: 1 [51200/60000(85%)]\tTrain Loss: 2.298548\n",
      "Train Epoch: 1 [57600/60000(96%)]\tTrain Loss: 2.272201\n",
      "\n",
      "[EPOCH: 1], \tTest Loss: 0.0712, \tTest Accuracy: 36.55 %\n",
      "\n",
      "Train Epoch: 2 [0/60000(0%)]\tTrain Loss: 2.301048\n",
      "Train Epoch: 2 [6400/60000(11%)]\tTrain Loss: 2.288892\n",
      "Train Epoch: 2 [12800/60000(21%)]\tTrain Loss: 2.279295\n",
      "Train Epoch: 2 [19200/60000(32%)]\tTrain Loss: 2.271452\n",
      "Train Epoch: 2 [25600/60000(43%)]\tTrain Loss: 2.278900\n",
      "Train Epoch: 2 [32000/60000(53%)]\tTrain Loss: 2.243847\n",
      "Train Epoch: 2 [38400/60000(64%)]\tTrain Loss: 2.296336\n",
      "Train Epoch: 2 [44800/60000(75%)]\tTrain Loss: 2.269730\n",
      "Train Epoch: 2 [51200/60000(85%)]\tTrain Loss: 2.218689\n",
      "Train Epoch: 2 [57600/60000(96%)]\tTrain Loss: 2.233280\n",
      "\n",
      "[EPOCH: 2], \tTest Loss: 0.0702, \tTest Accuracy: 32.68 %\n",
      "\n",
      "Train Epoch: 3 [0/60000(0%)]\tTrain Loss: 2.247474\n",
      "Train Epoch: 3 [6400/60000(11%)]\tTrain Loss: 2.269594\n",
      "Train Epoch: 3 [12800/60000(21%)]\tTrain Loss: 2.251569\n",
      "Train Epoch: 3 [19200/60000(32%)]\tTrain Loss: 2.240407\n",
      "Train Epoch: 3 [25600/60000(43%)]\tTrain Loss: 2.235556\n",
      "Train Epoch: 3 [32000/60000(53%)]\tTrain Loss: 2.201298\n",
      "Train Epoch: 3 [38400/60000(64%)]\tTrain Loss: 2.250125\n",
      "Train Epoch: 3 [44800/60000(75%)]\tTrain Loss: 2.152580\n",
      "Train Epoch: 3 [51200/60000(85%)]\tTrain Loss: 2.217176\n",
      "Train Epoch: 3 [57600/60000(96%)]\tTrain Loss: 2.218102\n",
      "\n",
      "[EPOCH: 3], \tTest Loss: 0.0677, \tTest Accuracy: 40.75 %\n",
      "\n",
      "Train Epoch: 4 [0/60000(0%)]\tTrain Loss: 2.170514\n",
      "Train Epoch: 4 [6400/60000(11%)]\tTrain Loss: 2.228253\n",
      "Train Epoch: 4 [12800/60000(21%)]\tTrain Loss: 2.148487\n",
      "Train Epoch: 4 [19200/60000(32%)]\tTrain Loss: 2.180165\n",
      "Train Epoch: 4 [25600/60000(43%)]\tTrain Loss: 2.150503\n",
      "Train Epoch: 4 [32000/60000(53%)]\tTrain Loss: 2.106327\n",
      "Train Epoch: 4 [38400/60000(64%)]\tTrain Loss: 2.147949\n",
      "Train Epoch: 4 [44800/60000(75%)]\tTrain Loss: 2.103361\n",
      "Train Epoch: 4 [51200/60000(85%)]\tTrain Loss: 2.124510\n",
      "Train Epoch: 4 [57600/60000(96%)]\tTrain Loss: 2.076938\n",
      "\n",
      "[EPOCH: 4], \tTest Loss: 0.0640, \tTest Accuracy: 53.31 %\n",
      "\n",
      "Train Epoch: 5 [0/60000(0%)]\tTrain Loss: 2.116785\n",
      "Train Epoch: 5 [6400/60000(11%)]\tTrain Loss: 2.068400\n",
      "Train Epoch: 5 [12800/60000(21%)]\tTrain Loss: 2.077332\n",
      "Train Epoch: 5 [19200/60000(32%)]\tTrain Loss: 2.070296\n",
      "Train Epoch: 5 [25600/60000(43%)]\tTrain Loss: 2.026490\n",
      "Train Epoch: 5 [32000/60000(53%)]\tTrain Loss: 2.029140\n",
      "Train Epoch: 5 [38400/60000(64%)]\tTrain Loss: 1.991889\n",
      "Train Epoch: 5 [44800/60000(75%)]\tTrain Loss: 2.005074\n",
      "Train Epoch: 5 [51200/60000(85%)]\tTrain Loss: 2.032569\n",
      "Train Epoch: 5 [57600/60000(96%)]\tTrain Loss: 1.967670\n",
      "\n",
      "[EPOCH: 5], \tTest Loss: 0.0613, \tTest Accuracy: 56.74 %\n",
      "\n",
      "Train Epoch: 6 [0/60000(0%)]\tTrain Loss: 1.975590\n",
      "Train Epoch: 6 [6400/60000(11%)]\tTrain Loss: 2.025028\n",
      "Train Epoch: 6 [12800/60000(21%)]\tTrain Loss: 1.970414\n",
      "Train Epoch: 6 [19200/60000(32%)]\tTrain Loss: 1.924667\n",
      "Train Epoch: 6 [25600/60000(43%)]\tTrain Loss: 1.952936\n",
      "Train Epoch: 6 [32000/60000(53%)]\tTrain Loss: 1.970955\n",
      "Train Epoch: 6 [38400/60000(64%)]\tTrain Loss: 1.920733\n",
      "Train Epoch: 6 [44800/60000(75%)]\tTrain Loss: 1.979635\n",
      "Train Epoch: 6 [51200/60000(85%)]\tTrain Loss: 1.970898\n",
      "Train Epoch: 6 [57600/60000(96%)]\tTrain Loss: 1.956741\n",
      "\n",
      "[EPOCH: 6], \tTest Loss: 0.0596, \tTest Accuracy: 59.13 %\n",
      "\n",
      "Train Epoch: 7 [0/60000(0%)]\tTrain Loss: 1.981441\n",
      "Train Epoch: 7 [6400/60000(11%)]\tTrain Loss: 1.921052\n",
      "Train Epoch: 7 [12800/60000(21%)]\tTrain Loss: 1.958790\n",
      "Train Epoch: 7 [19200/60000(32%)]\tTrain Loss: 1.954232\n",
      "Train Epoch: 7 [25600/60000(43%)]\tTrain Loss: 1.940013\n",
      "Train Epoch: 7 [32000/60000(53%)]\tTrain Loss: 1.877473\n",
      "Train Epoch: 7 [38400/60000(64%)]\tTrain Loss: 1.924588\n",
      "Train Epoch: 7 [44800/60000(75%)]\tTrain Loss: 1.932344\n",
      "Train Epoch: 7 [51200/60000(85%)]\tTrain Loss: 1.874503\n",
      "Train Epoch: 7 [57600/60000(96%)]\tTrain Loss: 1.883403\n",
      "\n",
      "[EPOCH: 7], \tTest Loss: 0.0585, \tTest Accuracy: 59.58 %\n",
      "\n",
      "Train Epoch: 8 [0/60000(0%)]\tTrain Loss: 1.881947\n",
      "Train Epoch: 8 [6400/60000(11%)]\tTrain Loss: 1.968396\n",
      "Train Epoch: 8 [12800/60000(21%)]\tTrain Loss: 1.978643\n",
      "Train Epoch: 8 [19200/60000(32%)]\tTrain Loss: 1.940424\n",
      "Train Epoch: 8 [25600/60000(43%)]\tTrain Loss: 1.853584\n",
      "Train Epoch: 8 [32000/60000(53%)]\tTrain Loss: 1.933359\n",
      "Train Epoch: 8 [38400/60000(64%)]\tTrain Loss: 1.907073\n",
      "Train Epoch: 8 [44800/60000(75%)]\tTrain Loss: 1.850158\n",
      "Train Epoch: 8 [51200/60000(85%)]\tTrain Loss: 1.855891\n",
      "Train Epoch: 8 [57600/60000(96%)]\tTrain Loss: 1.861387\n",
      "\n",
      "[EPOCH: 8], \tTest Loss: 0.0575, \tTest Accuracy: 61.86 %\n",
      "\n",
      "Train Epoch: 9 [0/60000(0%)]\tTrain Loss: 1.867602\n",
      "Train Epoch: 9 [6400/60000(11%)]\tTrain Loss: 1.797258\n",
      "Train Epoch: 9 [12800/60000(21%)]\tTrain Loss: 1.904998\n",
      "Train Epoch: 9 [19200/60000(32%)]\tTrain Loss: 1.871497\n",
      "Train Epoch: 9 [25600/60000(43%)]\tTrain Loss: 1.805198\n",
      "Train Epoch: 9 [32000/60000(53%)]\tTrain Loss: 1.848975\n",
      "Train Epoch: 9 [38400/60000(64%)]\tTrain Loss: 1.858336\n",
      "Train Epoch: 9 [44800/60000(75%)]\tTrain Loss: 1.833007\n",
      "Train Epoch: 9 [51200/60000(85%)]\tTrain Loss: 1.878762\n",
      "Train Epoch: 9 [57600/60000(96%)]\tTrain Loss: 1.862305\n",
      "\n",
      "[EPOCH: 9], \tTest Loss: 0.0567, \tTest Accuracy: 61.93 %\n",
      "\n",
      "Train Epoch: 10 [0/60000(0%)]\tTrain Loss: 1.863828\n",
      "Train Epoch: 10 [6400/60000(11%)]\tTrain Loss: 1.929599\n",
      "Train Epoch: 10 [12800/60000(21%)]\tTrain Loss: 1.817824\n",
      "Train Epoch: 10 [19200/60000(32%)]\tTrain Loss: 1.838287\n",
      "Train Epoch: 10 [25600/60000(43%)]\tTrain Loss: 1.842625\n",
      "Train Epoch: 10 [32000/60000(53%)]\tTrain Loss: 1.856922\n",
      "Train Epoch: 10 [38400/60000(64%)]\tTrain Loss: 1.825961\n",
      "Train Epoch: 10 [44800/60000(75%)]\tTrain Loss: 1.855413\n",
      "Train Epoch: 10 [51200/60000(85%)]\tTrain Loss: 1.876636\n",
      "Train Epoch: 10 [57600/60000(96%)]\tTrain Loss: 1.860672\n",
      "\n",
      "[EPOCH: 10], \tTest Loss: 0.0561, \tTest Accuracy: 61.62 %\n",
      "\n",
      "Train Epoch: 11 [0/60000(0%)]\tTrain Loss: 1.866301\n",
      "Train Epoch: 11 [6400/60000(11%)]\tTrain Loss: 1.848497\n",
      "Train Epoch: 11 [12800/60000(21%)]\tTrain Loss: 1.914972\n",
      "Train Epoch: 11 [19200/60000(32%)]\tTrain Loss: 1.837446\n",
      "Train Epoch: 11 [25600/60000(43%)]\tTrain Loss: 1.882680\n",
      "Train Epoch: 11 [32000/60000(53%)]\tTrain Loss: 1.784945\n",
      "Train Epoch: 11 [38400/60000(64%)]\tTrain Loss: 1.813266\n",
      "Train Epoch: 11 [44800/60000(75%)]\tTrain Loss: 1.822422\n",
      "Train Epoch: 11 [51200/60000(85%)]\tTrain Loss: 1.800115\n",
      "Train Epoch: 11 [57600/60000(96%)]\tTrain Loss: 1.779210\n",
      "\n",
      "[EPOCH: 11], \tTest Loss: 0.0558, \tTest Accuracy: 61.78 %\n",
      "\n",
      "Train Epoch: 12 [0/60000(0%)]\tTrain Loss: 1.808388\n",
      "Train Epoch: 12 [6400/60000(11%)]\tTrain Loss: 1.776360\n",
      "Train Epoch: 12 [12800/60000(21%)]\tTrain Loss: 1.781757\n",
      "Train Epoch: 12 [19200/60000(32%)]\tTrain Loss: 1.810284\n",
      "Train Epoch: 12 [25600/60000(43%)]\tTrain Loss: 1.826159\n",
      "Train Epoch: 12 [32000/60000(53%)]\tTrain Loss: 1.844722\n",
      "Train Epoch: 12 [38400/60000(64%)]\tTrain Loss: 1.893167\n",
      "Train Epoch: 12 [44800/60000(75%)]\tTrain Loss: 1.797753\n",
      "Train Epoch: 12 [51200/60000(85%)]\tTrain Loss: 1.823386\n",
      "Train Epoch: 12 [57600/60000(96%)]\tTrain Loss: 1.896884\n",
      "\n",
      "[EPOCH: 12], \tTest Loss: 0.0555, \tTest Accuracy: 61.52 %\n",
      "\n",
      "Train Epoch: 13 [0/60000(0%)]\tTrain Loss: 1.797216\n",
      "Train Epoch: 13 [6400/60000(11%)]\tTrain Loss: 1.766150\n",
      "Train Epoch: 13 [12800/60000(21%)]\tTrain Loss: 1.747659\n",
      "Train Epoch: 13 [19200/60000(32%)]\tTrain Loss: 1.797939\n",
      "Train Epoch: 13 [25600/60000(43%)]\tTrain Loss: 1.768194\n",
      "Train Epoch: 13 [32000/60000(53%)]\tTrain Loss: 1.877208\n",
      "Train Epoch: 13 [38400/60000(64%)]\tTrain Loss: 1.734855\n",
      "Train Epoch: 13 [44800/60000(75%)]\tTrain Loss: 1.801270\n",
      "Train Epoch: 13 [51200/60000(85%)]\tTrain Loss: 1.792860\n",
      "Train Epoch: 13 [57600/60000(96%)]\tTrain Loss: 1.749854\n",
      "\n",
      "[EPOCH: 13], \tTest Loss: 0.0552, \tTest Accuracy: 62.55 %\n",
      "\n",
      "Train Epoch: 14 [0/60000(0%)]\tTrain Loss: 1.802893\n",
      "Train Epoch: 14 [6400/60000(11%)]\tTrain Loss: 1.736533\n",
      "Train Epoch: 14 [12800/60000(21%)]\tTrain Loss: 1.825954\n",
      "Train Epoch: 14 [19200/60000(32%)]\tTrain Loss: 1.782330\n",
      "Train Epoch: 14 [25600/60000(43%)]\tTrain Loss: 1.840141\n",
      "Train Epoch: 14 [32000/60000(53%)]\tTrain Loss: 1.745569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [38400/60000(64%)]\tTrain Loss: 1.818341\n",
      "Train Epoch: 14 [44800/60000(75%)]\tTrain Loss: 1.770335\n",
      "Train Epoch: 14 [51200/60000(85%)]\tTrain Loss: 1.769101\n",
      "Train Epoch: 14 [57600/60000(96%)]\tTrain Loss: 1.729534\n",
      "\n",
      "[EPOCH: 14], \tTest Loss: 0.0550, \tTest Accuracy: 62.56 %\n",
      "\n",
      "Train Epoch: 15 [0/60000(0%)]\tTrain Loss: 1.807569\n",
      "Train Epoch: 15 [6400/60000(11%)]\tTrain Loss: 1.836169\n",
      "Train Epoch: 15 [12800/60000(21%)]\tTrain Loss: 1.782104\n",
      "Train Epoch: 15 [19200/60000(32%)]\tTrain Loss: 1.802412\n",
      "Train Epoch: 15 [25600/60000(43%)]\tTrain Loss: 1.924171\n",
      "Train Epoch: 15 [32000/60000(53%)]\tTrain Loss: 1.784240\n",
      "Train Epoch: 15 [38400/60000(64%)]\tTrain Loss: 1.742103\n",
      "Train Epoch: 15 [44800/60000(75%)]\tTrain Loss: 1.825655\n",
      "Train Epoch: 15 [51200/60000(85%)]\tTrain Loss: 1.779862\n",
      "Train Epoch: 15 [57600/60000(96%)]\tTrain Loss: 1.732509\n",
      "\n",
      "[EPOCH: 15], \tTest Loss: 0.0548, \tTest Accuracy: 61.64 %\n",
      "\n",
      "Train Epoch: 16 [0/60000(0%)]\tTrain Loss: 1.819848\n",
      "Train Epoch: 16 [6400/60000(11%)]\tTrain Loss: 1.731780\n",
      "Train Epoch: 16 [12800/60000(21%)]\tTrain Loss: 1.742651\n",
      "Train Epoch: 16 [19200/60000(32%)]\tTrain Loss: 1.753952\n",
      "Train Epoch: 16 [25600/60000(43%)]\tTrain Loss: 1.710077\n",
      "Train Epoch: 16 [32000/60000(53%)]\tTrain Loss: 1.707321\n",
      "Train Epoch: 16 [38400/60000(64%)]\tTrain Loss: 1.791279\n",
      "Train Epoch: 16 [44800/60000(75%)]\tTrain Loss: 1.830097\n",
      "Train Epoch: 16 [51200/60000(85%)]\tTrain Loss: 1.739907\n",
      "Train Epoch: 16 [57600/60000(96%)]\tTrain Loss: 1.789933\n",
      "\n",
      "[EPOCH: 16], \tTest Loss: 0.0547, \tTest Accuracy: 61.91 %\n",
      "\n",
      "Train Epoch: 17 [0/60000(0%)]\tTrain Loss: 1.716882\n",
      "Train Epoch: 17 [6400/60000(11%)]\tTrain Loss: 1.774333\n",
      "Train Epoch: 17 [12800/60000(21%)]\tTrain Loss: 1.822604\n",
      "Train Epoch: 17 [19200/60000(32%)]\tTrain Loss: 1.726542\n",
      "Train Epoch: 17 [25600/60000(43%)]\tTrain Loss: 1.822157\n",
      "Train Epoch: 17 [32000/60000(53%)]\tTrain Loss: 1.703989\n",
      "Train Epoch: 17 [38400/60000(64%)]\tTrain Loss: 1.773173\n",
      "Train Epoch: 17 [44800/60000(75%)]\tTrain Loss: 1.802817\n",
      "Train Epoch: 17 [51200/60000(85%)]\tTrain Loss: 1.745345\n",
      "Train Epoch: 17 [57600/60000(96%)]\tTrain Loss: 1.721230\n",
      "\n",
      "[EPOCH: 17], \tTest Loss: 0.0545, \tTest Accuracy: 61.51 %\n",
      "\n",
      "Train Epoch: 18 [0/60000(0%)]\tTrain Loss: 1.747571\n",
      "Train Epoch: 18 [6400/60000(11%)]\tTrain Loss: 1.754564\n",
      "Train Epoch: 18 [12800/60000(21%)]\tTrain Loss: 1.772058\n",
      "Train Epoch: 18 [19200/60000(32%)]\tTrain Loss: 1.774890\n",
      "Train Epoch: 18 [25600/60000(43%)]\tTrain Loss: 1.794985\n",
      "Train Epoch: 18 [32000/60000(53%)]\tTrain Loss: 1.839027\n",
      "Train Epoch: 18 [38400/60000(64%)]\tTrain Loss: 1.735397\n",
      "Train Epoch: 18 [44800/60000(75%)]\tTrain Loss: 1.752336\n",
      "Train Epoch: 18 [51200/60000(85%)]\tTrain Loss: 1.781450\n",
      "Train Epoch: 18 [57600/60000(96%)]\tTrain Loss: 1.728159\n",
      "\n",
      "[EPOCH: 18], \tTest Loss: 0.0544, \tTest Accuracy: 61.08 %\n",
      "\n",
      "Train Epoch: 19 [0/60000(0%)]\tTrain Loss: 1.828847\n",
      "Train Epoch: 19 [6400/60000(11%)]\tTrain Loss: 1.831177\n",
      "Train Epoch: 19 [12800/60000(21%)]\tTrain Loss: 1.823988\n",
      "Train Epoch: 19 [19200/60000(32%)]\tTrain Loss: 1.777343\n",
      "Train Epoch: 19 [25600/60000(43%)]\tTrain Loss: 1.831828\n",
      "Train Epoch: 19 [32000/60000(53%)]\tTrain Loss: 1.822965\n",
      "Train Epoch: 19 [38400/60000(64%)]\tTrain Loss: 1.785670\n",
      "Train Epoch: 19 [44800/60000(75%)]\tTrain Loss: 1.788275\n",
      "Train Epoch: 19 [51200/60000(85%)]\tTrain Loss: 1.759931\n",
      "Train Epoch: 19 [57600/60000(96%)]\tTrain Loss: 1.775001\n",
      "\n",
      "[EPOCH: 19], \tTest Loss: 0.0543, \tTest Accuracy: 60.65 %\n",
      "\n",
      "Train Epoch: 20 [0/60000(0%)]\tTrain Loss: 1.737362\n",
      "Train Epoch: 20 [6400/60000(11%)]\tTrain Loss: 1.760995\n",
      "Train Epoch: 20 [12800/60000(21%)]\tTrain Loss: 1.750062\n",
      "Train Epoch: 20 [19200/60000(32%)]\tTrain Loss: 1.803807\n",
      "Train Epoch: 20 [25600/60000(43%)]\tTrain Loss: 1.764942\n",
      "Train Epoch: 20 [32000/60000(53%)]\tTrain Loss: 1.792249\n",
      "Train Epoch: 20 [38400/60000(64%)]\tTrain Loss: 1.739375\n",
      "Train Epoch: 20 [44800/60000(75%)]\tTrain Loss: 1.757232\n",
      "Train Epoch: 20 [51200/60000(85%)]\tTrain Loss: 1.718751\n",
      "Train Epoch: 20 [57600/60000(96%)]\tTrain Loss: 1.761626\n",
      "\n",
      "[EPOCH: 20], \tTest Loss: 0.0542, \tTest Accuracy: 60.28 %\n",
      "\n",
      "Train Epoch: 21 [0/60000(0%)]\tTrain Loss: 1.733759\n",
      "Train Epoch: 21 [6400/60000(11%)]\tTrain Loss: 1.707256\n",
      "Train Epoch: 21 [12800/60000(21%)]\tTrain Loss: 1.708358\n",
      "Train Epoch: 21 [19200/60000(32%)]\tTrain Loss: 1.706252\n",
      "Train Epoch: 21 [25600/60000(43%)]\tTrain Loss: 1.703940\n",
      "Train Epoch: 21 [32000/60000(53%)]\tTrain Loss: 1.776563\n",
      "Train Epoch: 21 [38400/60000(64%)]\tTrain Loss: 1.801020\n",
      "Train Epoch: 21 [44800/60000(75%)]\tTrain Loss: 1.757422\n",
      "Train Epoch: 21 [51200/60000(85%)]\tTrain Loss: 1.771080\n",
      "Train Epoch: 21 [57600/60000(96%)]\tTrain Loss: 1.766169\n",
      "\n",
      "[EPOCH: 21], \tTest Loss: 0.0541, \tTest Accuracy: 59.45 %\n",
      "\n",
      "Train Epoch: 22 [0/60000(0%)]\tTrain Loss: 1.759802\n",
      "Train Epoch: 22 [6400/60000(11%)]\tTrain Loss: 1.802225\n",
      "Train Epoch: 22 [12800/60000(21%)]\tTrain Loss: 1.795269\n",
      "Train Epoch: 22 [19200/60000(32%)]\tTrain Loss: 1.808286\n",
      "Train Epoch: 22 [25600/60000(43%)]\tTrain Loss: 1.809534\n",
      "Train Epoch: 22 [32000/60000(53%)]\tTrain Loss: 1.808818\n",
      "Train Epoch: 22 [38400/60000(64%)]\tTrain Loss: 1.839278\n",
      "Train Epoch: 22 [44800/60000(75%)]\tTrain Loss: 1.778228\n",
      "Train Epoch: 22 [51200/60000(85%)]\tTrain Loss: 1.822952\n",
      "Train Epoch: 22 [57600/60000(96%)]\tTrain Loss: 1.789179\n",
      "\n",
      "[EPOCH: 22], \tTest Loss: 0.0540, \tTest Accuracy: 59.40 %\n",
      "\n",
      "Train Epoch: 23 [0/60000(0%)]\tTrain Loss: 1.741775\n",
      "Train Epoch: 23 [6400/60000(11%)]\tTrain Loss: 1.728572\n",
      "Train Epoch: 23 [12800/60000(21%)]\tTrain Loss: 1.719304\n",
      "Train Epoch: 23 [19200/60000(32%)]\tTrain Loss: 1.788252\n",
      "Train Epoch: 23 [25600/60000(43%)]\tTrain Loss: 1.669943\n",
      "Train Epoch: 23 [32000/60000(53%)]\tTrain Loss: 1.738804\n",
      "Train Epoch: 23 [38400/60000(64%)]\tTrain Loss: 1.751944\n",
      "Train Epoch: 23 [44800/60000(75%)]\tTrain Loss: 1.684871\n",
      "Train Epoch: 23 [51200/60000(85%)]\tTrain Loss: 1.824459\n",
      "Train Epoch: 23 [57600/60000(96%)]\tTrain Loss: 1.712438\n",
      "\n",
      "[EPOCH: 23], \tTest Loss: 0.0539, \tTest Accuracy: 58.78 %\n",
      "\n",
      "Train Epoch: 24 [0/60000(0%)]\tTrain Loss: 1.737669\n",
      "Train Epoch: 24 [6400/60000(11%)]\tTrain Loss: 1.756953\n",
      "Train Epoch: 24 [12800/60000(21%)]\tTrain Loss: 1.708203\n",
      "Train Epoch: 24 [19200/60000(32%)]\tTrain Loss: 1.742728\n",
      "Train Epoch: 24 [25600/60000(43%)]\tTrain Loss: 1.691515\n",
      "Train Epoch: 24 [32000/60000(53%)]\tTrain Loss: 1.757781\n",
      "Train Epoch: 24 [38400/60000(64%)]\tTrain Loss: 1.765595\n",
      "Train Epoch: 24 [44800/60000(75%)]\tTrain Loss: 1.719405\n",
      "Train Epoch: 24 [51200/60000(85%)]\tTrain Loss: 1.735361\n",
      "Train Epoch: 24 [57600/60000(96%)]\tTrain Loss: 1.729595\n",
      "\n",
      "[EPOCH: 24], \tTest Loss: 0.0538, \tTest Accuracy: 57.73 %\n",
      "\n",
      "Train Epoch: 25 [0/60000(0%)]\tTrain Loss: 1.727662\n",
      "Train Epoch: 25 [6400/60000(11%)]\tTrain Loss: 1.763519\n",
      "Train Epoch: 25 [12800/60000(21%)]\tTrain Loss: 1.744044\n",
      "Train Epoch: 25 [19200/60000(32%)]\tTrain Loss: 1.724613\n",
      "Train Epoch: 25 [25600/60000(43%)]\tTrain Loss: 1.712278\n",
      "Train Epoch: 25 [32000/60000(53%)]\tTrain Loss: 1.715440\n",
      "Train Epoch: 25 [38400/60000(64%)]\tTrain Loss: 1.687286\n",
      "Train Epoch: 25 [44800/60000(75%)]\tTrain Loss: 1.753132\n",
      "Train Epoch: 25 [51200/60000(85%)]\tTrain Loss: 1.794358\n",
      "Train Epoch: 25 [57600/60000(96%)]\tTrain Loss: 1.776688\n",
      "\n",
      "[EPOCH: 25], \tTest Loss: 0.0538, \tTest Accuracy: 57.57 %\n",
      "\n",
      "Train Epoch: 26 [0/60000(0%)]\tTrain Loss: 1.786695\n",
      "Train Epoch: 26 [6400/60000(11%)]\tTrain Loss: 1.771362\n",
      "Train Epoch: 26 [12800/60000(21%)]\tTrain Loss: 1.712672\n",
      "Train Epoch: 26 [19200/60000(32%)]\tTrain Loss: 1.690632\n",
      "Train Epoch: 26 [25600/60000(43%)]\tTrain Loss: 1.696879\n",
      "Train Epoch: 26 [32000/60000(53%)]\tTrain Loss: 1.714211\n",
      "Train Epoch: 26 [38400/60000(64%)]\tTrain Loss: 1.670879\n",
      "Train Epoch: 26 [44800/60000(75%)]\tTrain Loss: 1.711842\n",
      "Train Epoch: 26 [51200/60000(85%)]\tTrain Loss: 1.778004\n",
      "Train Epoch: 26 [57600/60000(96%)]\tTrain Loss: 1.713136\n",
      "\n",
      "[EPOCH: 26], \tTest Loss: 0.0537, \tTest Accuracy: 57.15 %\n",
      "\n",
      "Train Epoch: 27 [0/60000(0%)]\tTrain Loss: 1.723745\n",
      "Train Epoch: 27 [6400/60000(11%)]\tTrain Loss: 1.726939\n",
      "Train Epoch: 27 [12800/60000(21%)]\tTrain Loss: 1.696860\n",
      "Train Epoch: 27 [19200/60000(32%)]\tTrain Loss: 1.800435\n",
      "Train Epoch: 27 [25600/60000(43%)]\tTrain Loss: 1.737155\n",
      "Train Epoch: 27 [32000/60000(53%)]\tTrain Loss: 1.701273\n",
      "Train Epoch: 27 [38400/60000(64%)]\tTrain Loss: 1.783008\n",
      "Train Epoch: 27 [44800/60000(75%)]\tTrain Loss: 1.684243\n",
      "Train Epoch: 27 [51200/60000(85%)]\tTrain Loss: 1.823696\n",
      "Train Epoch: 27 [57600/60000(96%)]\tTrain Loss: 1.709710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH: 27], \tTest Loss: 0.0536, \tTest Accuracy: 58.54 %\n",
      "\n",
      "Train Epoch: 28 [0/60000(0%)]\tTrain Loss: 1.705284\n",
      "Train Epoch: 28 [6400/60000(11%)]\tTrain Loss: 1.695643\n",
      "Train Epoch: 28 [12800/60000(21%)]\tTrain Loss: 1.730115\n",
      "Train Epoch: 28 [19200/60000(32%)]\tTrain Loss: 1.831147\n",
      "Train Epoch: 28 [25600/60000(43%)]\tTrain Loss: 1.697977\n",
      "Train Epoch: 28 [32000/60000(53%)]\tTrain Loss: 1.724148\n",
      "Train Epoch: 28 [38400/60000(64%)]\tTrain Loss: 1.676481\n",
      "Train Epoch: 28 [44800/60000(75%)]\tTrain Loss: 1.694937\n",
      "Train Epoch: 28 [51200/60000(85%)]\tTrain Loss: 1.718991\n",
      "Train Epoch: 28 [57600/60000(96%)]\tTrain Loss: 1.685880\n",
      "\n",
      "[EPOCH: 28], \tTest Loss: 0.0536, \tTest Accuracy: 56.67 %\n",
      "\n",
      "Train Epoch: 29 [0/60000(0%)]\tTrain Loss: 1.733369\n",
      "Train Epoch: 29 [6400/60000(11%)]\tTrain Loss: 1.696751\n",
      "Train Epoch: 29 [12800/60000(21%)]\tTrain Loss: 1.799235\n",
      "Train Epoch: 29 [19200/60000(32%)]\tTrain Loss: 1.733144\n",
      "Train Epoch: 29 [25600/60000(43%)]\tTrain Loss: 1.697622\n",
      "Train Epoch: 29 [32000/60000(53%)]\tTrain Loss: 1.728076\n",
      "Train Epoch: 29 [38400/60000(64%)]\tTrain Loss: 1.699536\n",
      "Train Epoch: 29 [44800/60000(75%)]\tTrain Loss: 1.734550\n",
      "Train Epoch: 29 [51200/60000(85%)]\tTrain Loss: 1.711939\n",
      "Train Epoch: 29 [57600/60000(96%)]\tTrain Loss: 1.689874\n",
      "\n",
      "[EPOCH: 29], \tTest Loss: 0.0535, \tTest Accuracy: 57.42 %\n",
      "\n",
      "Train Epoch: 30 [0/60000(0%)]\tTrain Loss: 1.698188\n",
      "Train Epoch: 30 [6400/60000(11%)]\tTrain Loss: 1.755677\n",
      "Train Epoch: 30 [12800/60000(21%)]\tTrain Loss: 1.755911\n",
      "Train Epoch: 30 [19200/60000(32%)]\tTrain Loss: 1.745035\n",
      "Train Epoch: 30 [25600/60000(43%)]\tTrain Loss: 1.727505\n",
      "Train Epoch: 30 [32000/60000(53%)]\tTrain Loss: 1.689144\n",
      "Train Epoch: 30 [38400/60000(64%)]\tTrain Loss: 1.695295\n",
      "Train Epoch: 30 [44800/60000(75%)]\tTrain Loss: 1.663855\n",
      "Train Epoch: 30 [51200/60000(85%)]\tTrain Loss: 1.755349\n",
      "Train Epoch: 30 [57600/60000(96%)]\tTrain Loss: 1.718944\n",
      "\n",
      "[EPOCH: 30], \tTest Loss: 0.0534, \tTest Accuracy: 57.35 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLP 학습시키며 Train, Test set의 Loss 및 Test set Accuracy를 확인\n",
    "for Epoch in range(1, EPOCHS+1):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\\n\".format(Epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
